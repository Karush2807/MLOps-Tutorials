MLOps Bootcamp :)

step_01: requirement gathering (product experts/domain)
step_02: data analyst/data scientist -(will be identifying source of data annd will also see which data is essential or  not
step_03: big data engineering team will come that come in place ETL pipelines/(apache airflow[help us to schedule with this tool]))
then this data stored in a databse and it keeps on updating

# life cycle of a data science project: 
1. feature egineering
2. feature selection
3. model creation and hyper parameter training
here will be using mlFLow (will deploy in remot repo or aws )for expermient tracking
4. clous used: aws and azure
5. model monitoring ( will used grafana )


# list of ml tools: 
1. airflow
2. mlflow
3. astronomer (cloud platform to deploy airflow)
4. aws/azure.aws-sazemker
5. github actions ( for automating)
6. mongodb for storage
6. docker for containerisation
8. dagsHub(remote repostiroy)
